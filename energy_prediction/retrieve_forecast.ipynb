{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygrib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile\n",
    "import logging\n",
    "import sys\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from pvlib import pvsystem, modelchain, location, irradiance\n",
    "from pvlib.solarposition import get_solarposition\n",
    "from pvlib import irradiance, solarposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetching latest file of harmonie_arome_cy40_p1 version 0.2\n",
      "INFO:__main__:Latest file is: harm40_v1_p1_2024053100.tar\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 74\u001b[0m\n\u001b[0;32m     70\u001b[0m     download_file_from_temporary_download_url(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemporaryDownloadUrl\u001b[39m\u001b[38;5;124m\"\u001b[39m], latest_file)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 74\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[103], line 70\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# fetch the download url and download the file\u001b[39;00m\n\u001b[0;32m     69\u001b[0m response \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mget_file_url(dataset_name, dataset_version, latest_file)\n\u001b[1;32m---> 70\u001b[0m download_file_from_temporary_download_url(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemporaryDownloadUrl\u001b[39m\u001b[38;5;124m\"\u001b[39m], latest_file)\n",
      "Cell \u001b[1;32mIn[103], line 31\u001b[0m, in \u001b[0;36mdownload_file_from_temporary_download_url\u001b[1;34m(download_url, filename)\u001b[0m\n\u001b[0;32m     29\u001b[0m         r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 31\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8192\u001b[39m):\n\u001b[0;32m     32\u001b[0m                 f\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\20193362\\AppData\\Local\\anaconda3\\Lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\20193362\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:936\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 936\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(amt\u001b[38;5;241m=\u001b[39mamt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m    939\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\20193362\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[0;32m    877\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[1;32m--> 879\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_read(amt)\n\u001b[0;32m    881\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\20193362\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:814\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    811\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 814\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp_read(amt) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    824\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\20193362\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:799\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 799\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\20193362\\AppData\\Local\\anaconda3\\Lib\\http\\client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    472\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 473\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Users\\20193362\\AppData\\Local\\anaconda3\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\20193362\\AppData\\Local\\anaconda3\\Lib\\ssl.py:1315\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1314\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\20193362\\AppData\\Local\\anaconda3\\Lib\\ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logging.basicConfig()\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(os.environ.get(\"LOG_LEVEL\", logging.INFO))\n",
    "\n",
    "\n",
    "class OpenDataAPI:\n",
    "    def __init__(self, api_token: str):\n",
    "        self.base_url = \"https://api.dataplatform.knmi.nl/open-data/v1\"\n",
    "        self.headers = {\"Authorization\": api_token}\n",
    "\n",
    "    def __get_data(self, url, params=None):\n",
    "        return requests.get(url, headers=self.headers, params=params).json()\n",
    "\n",
    "    def list_files(self, dataset_name: str, dataset_version: str, params: dict):\n",
    "        return self.__get_data(\n",
    "            f\"{self.base_url}/datasets/{dataset_name}/versions/{dataset_version}/files\",\n",
    "            params=params,\n",
    "        )\n",
    "\n",
    "    def get_file_url(self, dataset_name: str, dataset_version: str, file_name: str):\n",
    "        return self.__get_data(\n",
    "            f\"{self.base_url}/datasets/{dataset_name}/versions/{dataset_version}/files/{file_name}/url\"\n",
    "        )\n",
    "\n",
    "\n",
    "def download_file_from_temporary_download_url(download_url, filename):\n",
    "    try:\n",
    "        with requests.get(download_url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(filename, \"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "    except Exception:\n",
    "        logger.exception(\"Unable to download file using download URL\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    logger.info(f\"Successfully downloaded dataset file to {filename}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    api_key = \"eyJvcmciOiI1ZTU1NGUxOTI3NGE5NjAwMDEyYTNlYjEiLCJpZCI6ImE1OGI5NGZmMDY5NDRhZDNhZjFkMDBmNDBmNTQyNjBkIiwiaCI6Im11cm11cjEyOCJ9\"\n",
    "    dataset_name = \"harmonie_arome_cy40_p1\"\n",
    "    dataset_version = \"0.2\"\n",
    "    logger.info(f\"Fetching latest file of {dataset_name} version {dataset_version}\")\n",
    "\n",
    "    api = OpenDataAPI(api_token=api_key)\n",
    "\n",
    "    # sort the files in descending order and only retrieve the first file\n",
    "    params = {\"maxKeys\": 4, \"orderBy\": \"created\", \"sorting\": \"desc\"}\n",
    "    response = api.list_files(dataset_name, dataset_version, params)\n",
    "    # print(response)\n",
    "    if \"error\" in response:\n",
    "        logger.error(f\"Unable to retrieve list of files: {response['error']}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    \n",
    "    # Filter files that end with '00.tar'\n",
    "    filtered_files = [f for f in response[\"files\"] if f.get(\"filename\").endswith(\"00.tar\")]\n",
    "    \n",
    "    if not filtered_files:\n",
    "        logger.error(\"No files ending with '00.tar' found\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Assuming files are already sorted by creation date in the response, get the latest\n",
    "    latest_file = filtered_files[0].get(\"filename\")\n",
    "    logger.info(f\"Latest file is: {latest_file}\")\n",
    "\n",
    "    # fetch the download url and download the file\n",
    "    response = api.get_file_url(dataset_name, dataset_version, latest_file)\n",
    "    download_file_from_temporary_download_url(response[\"temporaryDownloadUrl\"], latest_file)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unpack_tar_file(tar_path):\n",
    "    # Create destination folder path\n",
    "    dest_folder = os.path.join(os.path.dirname(tar_path), os.path.basename(tar_path).rsplit('.', 1)[0])\n",
    "    os.makedirs(dest_folder, exist_ok=True)  # Ensure the destination folder exists\n",
    "    \n",
    "    # Extract all contents of file in destination folder path\n",
    "    with tarfile.open(tar_path, \"r\") as tar:\n",
    "        tar.extractall(path=dest_folder)\n",
    "\n",
    "# Replace with the path to your tar file\n",
    "tar_path = \"harm40_v1_p1_2024052900.tar\"\n",
    "unpack_tar_file(tar_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         file_name            datetime  temperature  \\\n",
      "0   HA40_N25_202405290000_00000_GB 2024-05-29 00:00:00    15.719385   \n",
      "1   HA40_N25_202405290000_00100_GB 2024-05-29 01:00:00    15.551904   \n",
      "2   HA40_N25_202405290000_00200_GB 2024-05-29 02:00:00    15.408838   \n",
      "3   HA40_N25_202405290000_00300_GB 2024-05-29 03:00:00    15.307031   \n",
      "4   HA40_N25_202405290000_00400_GB 2024-05-29 04:00:00    15.463770   \n",
      "5   HA40_N25_202405290000_00500_GB 2024-05-29 05:00:00    15.528223   \n",
      "6   HA40_N25_202405290000_00600_GB 2024-05-29 06:00:00    15.560327   \n",
      "7   HA40_N25_202405290000_00700_GB 2024-05-29 07:00:00    15.804834   \n",
      "8   HA40_N25_202405290000_00800_GB 2024-05-29 08:00:00    16.125879   \n",
      "9   HA40_N25_202405290000_00900_GB 2024-05-29 09:00:00    15.691064   \n",
      "10  HA40_N25_202405290000_01000_GB 2024-05-29 10:00:00    15.560693   \n",
      "11  HA40_N25_202405290000_01100_GB 2024-05-29 11:00:00    15.911768   \n",
      "12  HA40_N25_202405290000_01200_GB 2024-05-29 12:00:00    16.234033   \n",
      "13  HA40_N25_202405290000_01300_GB 2024-05-29 13:00:00    16.919336   \n",
      "14  HA40_N25_202405290000_01400_GB 2024-05-29 14:00:00    15.900049   \n",
      "15  HA40_N25_202405290000_01500_GB 2024-05-29 15:00:00    17.116846   \n",
      "16  HA40_N25_202405290000_01600_GB 2024-05-29 16:00:00    18.352197   \n",
      "17  HA40_N25_202405290000_01700_GB 2024-05-29 17:00:00    17.209131   \n",
      "18  HA40_N25_202405290000_01800_GB 2024-05-29 18:00:00    15.899072   \n",
      "19  HA40_N25_202405290000_01900_GB 2024-05-29 19:00:00    16.193262   \n",
      "20  HA40_N25_202405290000_02000_GB 2024-05-29 20:00:00    15.769434   \n",
      "21  HA40_N25_202405290000_02100_GB 2024-05-29 21:00:00    14.701929   \n",
      "22  HA40_N25_202405290000_02200_GB 2024-05-29 22:00:00    13.814844   \n",
      "23  HA40_N25_202405290000_02300_GB 2024-05-29 23:00:00    13.411890   \n",
      "24  HA40_N25_202405290000_02400_GB 2024-05-30 00:00:00    13.755884   \n",
      "25  HA40_N25_202405290000_02500_GB 2024-05-30 01:00:00    13.068994   \n",
      "26  HA40_N25_202405290000_02600_GB 2024-05-30 02:00:00    13.010400   \n",
      "27  HA40_N25_202405290000_02700_GB 2024-05-30 03:00:00    13.000146   \n",
      "28  HA40_N25_202405290000_02800_GB 2024-05-30 04:00:00    12.647119   \n",
      "29  HA40_N25_202405290000_02900_GB 2024-05-30 05:00:00    12.670313   \n",
      "30  HA40_N25_202405290000_03000_GB 2024-05-30 06:00:00    12.887231   \n",
      "31  HA40_N25_202405290000_03100_GB 2024-05-30 07:00:00    13.670557   \n",
      "32  HA40_N25_202405290000_03200_GB 2024-05-30 08:00:00    14.857568   \n",
      "33  HA40_N25_202405290000_03300_GB 2024-05-30 09:00:00    16.439111   \n",
      "34  HA40_N25_202405290000_03400_GB 2024-05-30 10:00:00    15.591943   \n",
      "35  HA40_N25_202405290000_03500_GB 2024-05-30 11:00:00    14.820947   \n",
      "36  HA40_N25_202405290000_03600_GB 2024-05-30 12:00:00    16.170068   \n",
      "37  HA40_N25_202405290000_03700_GB 2024-05-30 13:00:00    17.213525   \n",
      "38  HA40_N25_202405290000_03800_GB 2024-05-30 14:00:00    17.459131   \n",
      "39  HA40_N25_202405290000_03900_GB 2024-05-30 15:00:00    18.316309   \n",
      "40  HA40_N25_202405290000_04000_GB 2024-05-30 16:00:00    17.558984   \n",
      "41  HA40_N25_202405290000_04100_GB 2024-05-30 17:00:00    16.327539   \n",
      "42  HA40_N25_202405290000_04200_GB 2024-05-30 18:00:00    15.581201   \n",
      "43  HA40_N25_202405290000_04300_GB 2024-05-30 19:00:00    15.039941   \n",
      "44  HA40_N25_202405290000_04400_GB 2024-05-30 20:00:00    14.758203   \n",
      "45  HA40_N25_202405290000_04500_GB 2024-05-30 21:00:00    14.470850   \n",
      "46  HA40_N25_202405290000_04600_GB 2024-05-30 22:00:00    14.202051   \n",
      "47  HA40_N25_202405290000_04700_GB 2024-05-30 23:00:00    13.563379   \n",
      "\n",
      "    globalRadiation  windSpeed             Q          dni           dhi  \n",
      "0      0.000000e+00   0.000000  0.000000e+00     0.000000  0.000000e+00  \n",
      "1      5.228093e-11   5.042000  1.452248e-14     0.000000  1.452248e-14  \n",
      "2      0.000000e+00   5.007828 -1.452248e-14     0.000000 -1.452248e-14  \n",
      "3      0.000000e+00   5.189025  0.000000e+00     0.000000  0.000000e+00  \n",
      "4      2.920000e+02   5.641888  8.111111e-02     0.000118  8.110467e-02  \n",
      "5      1.116205e+04   5.384340  3.019457e+00     0.014580  3.016548e+00  \n",
      "6      6.648036e+04   4.500063  1.536620e+01     0.122185  1.532335e+01  \n",
      "7      2.744221e+05   5.330915  5.776160e+01     0.857276  5.733491e+01  \n",
      "8      7.907008e+05   5.146894  1.434107e+02     3.293229  1.413343e+02  \n",
      "9      1.235848e+06   5.037259  1.236521e+02     1.777334  1.223369e+02  \n",
      "10     1.563320e+06   4.869860  9.096418e+01     0.785673  9.032085e+01  \n",
      "11     2.229969e+06   5.006302  1.851804e+02     2.941341  1.826463e+02  \n",
      "12     3.054872e+06   4.621871  2.291398e+02     4.465065  2.252761e+02  \n",
      "13     3.709425e+06   5.917071  1.818202e+02     3.057194  1.792833e+02  \n",
      "14     4.105818e+06   5.028545  1.101092e+02     1.345536  1.090899e+02  \n",
      "15     5.508865e+06   4.298146  3.897353e+02   116.043919  3.139142e+02  \n",
      "16     7.167069e+06   4.026036  4.606121e+02   533.614951  1.807475e+02  \n",
      "17     7.854929e+06   3.217602  1.910722e+02    51.750396  1.714286e+02  \n",
      "18     7.884881e+06   2.570625  8.320174e+00     0.084405  8.300878e+00  \n",
      "19     8.256346e+06   2.027663  1.031847e+02  1052.893392  1.702548e+01  \n",
      "20     8.304986e+06   2.359244  1.351111e+01     0.000000  1.351111e+01  \n",
      "21     8.304986e+06   2.106431  0.000000e+00     0.000000  0.000000e+00  \n",
      "22     8.304986e+06   1.480637  0.000000e+00     0.000000  0.000000e+00  \n",
      "23     8.304986e+06   1.513105  0.000000e+00     0.000000  0.000000e+00  \n",
      "24     8.304986e+06   1.771766  0.000000e+00     0.000000  0.000000e+00  \n",
      "25     8.304986e+06   1.917604  0.000000e+00     0.000000  0.000000e+00  \n",
      "26     8.304986e+06   1.946275  0.000000e+00     0.000000  0.000000e+00  \n",
      "27     8.304986e+06   2.102474  0.000000e+00     0.000000  0.000000e+00  \n",
      "28     8.321664e+06   1.919065  4.632552e+00     0.375207  4.611470e+00  \n",
      "29     8.385457e+06   2.114996  1.772050e+01     0.495756  1.762079e+01  \n",
      "30     8.454826e+06   2.098454  1.926917e+01     0.191243  1.920181e+01  \n",
      "31     8.908779e+06   2.373136  1.260980e+02     4.079840  1.240619e+02  \n",
      "32     9.639859e+06   1.893717  2.030778e+02     6.841299  1.987558e+02  \n",
      "33     1.086920e+07   1.889019  3.414847e+02    33.698967  3.165066e+02  \n",
      "34     1.173612e+07   3.264710  2.408092e+02     5.515951  2.362860e+02  \n",
      "35     1.182814e+07   2.623496  2.556167e+01     0.056160  2.551321e+01  \n",
      "36     1.232291e+07   3.082946  1.374356e+02     1.609693  1.360406e+02  \n",
      "37     1.358916e+07   4.210893  3.517369e+02    22.046805  3.334105e+02  \n",
      "38     1.479200e+07   3.498720  3.341231e+02    26.927263  3.136820e+02  \n",
      "39     1.643176e+07   4.171213  4.554872e+02   229.662441  3.050264e+02  \n",
      "40     1.756419e+07   4.566031  3.145653e+02   119.603553  2.516056e+02  \n",
      "41     1.840233e+07   4.374690  2.328172e+02   131.357455  1.826794e+02  \n",
      "42     1.901450e+07   4.054575  1.700475e+02   290.119464  1.030688e+02  \n",
      "43     1.916529e+07   3.314780  4.188500e+01    50.142342  3.766235e+01  \n",
      "44     1.918545e+07   2.538556  5.600278e+00     0.000000  5.600278e+00  \n",
      "45     1.918545e+07   2.833537  0.000000e+00     0.000000  0.000000e+00  \n",
      "46     1.918545e+07   2.556492  0.000000e+00     0.000000  0.000000e+00  \n",
      "47     1.918545e+07   2.476448  0.000000e+00     0.000000  0.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "# Eindhoven\n",
    "eindhoven_lat = 51.4416\n",
    "eindhoven_lon = 5.4697\n",
    "\n",
    "# Folder grib files\n",
    "grib_folder = r\"C:\\Users\\20193362\\Desktop\\InterProject\\InterdisciplinaryProject\\energy_prediction\\harm40_v1_p1_2024052900\"\n",
    "\n",
    "# List needed parameters, see code matrix KNMI\n",
    "parameters = {\"temperature\": \"11\", \"windU\": \"33\", \"windV\": \"34\", \"globalRadiation\":  \"117\"}\n",
    "\n",
    "# Initialize list to hold the data\n",
    "data_list = []\n",
    "\n",
    "# Loop over each file \n",
    "for file_name in os.listdir(grib_folder):\n",
    "    if file_name.endswith('_GB'):\n",
    "        grib_file = os.path.join(grib_folder, file_name)\n",
    "        grbs = pygrib.open(grib_file)\n",
    "        \n",
    "        # Retrieve the lat/lon grid\n",
    "        first_message = grbs.message(1)\n",
    "        lats, lons = first_message.latlons()\n",
    "        \n",
    "        # Find the closest grid point\n",
    "        distance = np.sqrt((lats - eindhoven_lat)**2 + (lons - eindhoven_lon)**2)\n",
    "        min_index = distance.argmin()\n",
    "        nearest_point_lat = lats.flat[min_index]\n",
    "        nearest_point_lon = lons.flat[min_index]\n",
    "\n",
    "        data_date = str(first_message.dataDate)  # Format: YYYYMMDD\n",
    "        data_time = first_message.dataTime  # Format: HHMM\n",
    "        \n",
    "        # Create the base datetime object from dataDate and dataTime\n",
    "        base_datetime = datetime.strptime(f\"{data_date} {data_time:04d}\", \"%Y%m%d %H%M\")\n",
    "        step_range = float(first_message.stepRange)\n",
    "        valid_datetime = base_datetime + timedelta(hours=step_range)\n",
    "        \n",
    "        # Initialize a dictionary to hold the data for this file\n",
    "        data_dict = {\n",
    "            'file_name': file_name,\n",
    "            'datetime': valid_datetime #,\n",
    "            #'latitude': nearest_point_lat,\n",
    "            #'longitude': nearest_point_lon\n",
    "        }\n",
    "        \n",
    "        # Extract data for each parameter\n",
    "        for param_name in parameters:\n",
    "            try:\n",
    "                grb_message = grbs.select(parameterName=parameters[param_name])[0] # First instance\n",
    "                eindhoven_value = grb_message.values.flat[min_index]\n",
    "                data_dict[param_name] = eindhoven_value\n",
    "            except (IndexError, ValueError):\n",
    "                data_dict[param_name] = np.nan # When parameter is not found in grib file\n",
    "        \n",
    "        grbs.close()\n",
    "        \n",
    "        # Append dictionary to list\n",
    "        data_list.append(data_dict)\n",
    "\n",
    "# Convert list of dictionaries to DF\n",
    "gribData = pd.DataFrame(data_list)\n",
    "df = gribData.copy()\n",
    "\n",
    "df['windSpeed'] = np.sqrt(df['windU']**2 + df['windV']**2)\n",
    "df['temperature'] = df['temperature'] - 272.15\n",
    "\n",
    "df['globalRadiation'] = df['globalRadiation'].fillna(0)\n",
    "# Calculate the difference between consecutive rows\n",
    "df['Q'] = df['globalRadiation'].diff()\n",
    "df['Q'] = df ['Q'] / 3600\n",
    "\n",
    "weather_df = df.copy()\n",
    "# Get solar position for the dates / times\n",
    "solpos_df = solarposition.get_solarposition(\n",
    "    weather_df['datetime'], latitude=eindhoven_lat,\n",
    "    longitude=eindhoven_lon, altitude=0,\n",
    "    temperature=weather_df['temperature']\n",
    ")\n",
    "solpos_df.index = weather_df.index\n",
    "\n",
    "# Method 'Erbs' to go from GHI to DNI and DHI\n",
    "irradiance_df = irradiance.erbs(weather_df['Q'], solpos_df['zenith'], weather_df.index)\n",
    "irradiance_df['ghi'] = weather_df['Q']\n",
    "\n",
    "# Add DNI and DHI to weather_df\n",
    "weather_df['dni'] = irradiance_df['dni']\n",
    "weather_df['dhi'] = irradiance_df['dhi']\n",
    "\n",
    "df = weather_df.copy()\n",
    "df = df.drop(['windU', 'windV'], axis=1)\n",
    "df = df[:-1]\n",
    "df = df.fillna(0)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         temperature_sequence  \\\n",
      "date                                                            \n",
      "2024-05-29  [15.719384765625023, 15.551904296875023, 15.40...   \n",
      "2024-05-30  [13.755883789062523, 13.068994140625023, 13.01...   \n",
      "\n",
      "                                          wind_speed_sequence  \\\n",
      "date                                                            \n",
      "2024-05-29  [0.0, 5.041999640192526, 5.007828251785629, 5....   \n",
      "2024-05-30  [1.7717661479428932, 1.9176039515453165, 1.946...   \n",
      "\n",
      "                                                 dni_sequence  \\\n",
      "date                                                            \n",
      "2024-05-29  [0.0, 0.0, 0.0, 0.0, 0.00011847502907301761, 0...   \n",
      "2024-05-30  [0.0, 0.0, 0.0, 0.0, 0.3752065591863343, 0.495...   \n",
      "\n",
      "                                                 dhi_sequence  \\\n",
      "date                                                            \n",
      "2024-05-29  [0.0, 1.4522480440426476e-14, -1.4522480440426...   \n",
      "2024-05-30  [0.0, 0.0, 0.0, 0.0, 4.611470368404375, 17.620...   \n",
      "\n",
      "                                   global_irradiance_sequence  \n",
      "date                                                           \n",
      "2024-05-29  [0.0, 5.228092958553532e-11, 0.0, 0.0, 292.0, ...  \n",
      "2024-05-30  [8304986.375, 8304986.375, 8304986.375, 830498...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Group by date\n",
    "df['date'] = df['datetime'].dt.date\n",
    "df = df.drop(['file_name', 'datetime'], axis=1)\n",
    "grouped = df.groupby('date')\n",
    "\n",
    "# Aggregate hourly values into lists per day\n",
    "daily_data = grouped.agg(list)\n",
    "keeps = {\n",
    "    'temperature':'temperature_sequence',\n",
    "    'windSpeed':'wind_speed_sequence',\n",
    "    'dni':'dni_sequence',\n",
    "    'dhi':'dhi_sequence',\n",
    "    'globalRadiation':'global_irradiance_sequence'\n",
    "    }\n",
    "daily_data=daily_data[keeps.keys()].rename(keeps,axis=1)\n",
    "daily_data.index.name = 'date'\n",
    "\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(daily_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "os.makedirs('energy_data', exist_ok=True)  \n",
    "daily_data.to_csv('energy_data/forecastweather48h.csv')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
