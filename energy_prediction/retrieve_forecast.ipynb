{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygrib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile\n",
    "import logging\n",
    "import sys\n",
    "import requests\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetching latest file of harmonie_arome_cy40_p1 version 0.2\n",
      "INFO:__main__:Latest file is: harm40_v1_p1_2024052906.tar\n",
      "INFO:__main__:Successfully downloaded dataset file to harm40_v1_p1_2024052906.tar\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig()\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(os.environ.get(\"LOG_LEVEL\", logging.INFO))\n",
    "\n",
    "\n",
    "class OpenDataAPI:\n",
    "    def __init__(self, api_token: str):\n",
    "        self.base_url = \"https://api.dataplatform.knmi.nl/open-data/v1\"\n",
    "        self.headers = {\"Authorization\": api_token}\n",
    "\n",
    "    def __get_data(self, url, params=None):\n",
    "        return requests.get(url, headers=self.headers, params=params).json()\n",
    "\n",
    "    def list_files(self, dataset_name: str, dataset_version: str, params: dict):\n",
    "        return self.__get_data(\n",
    "            f\"{self.base_url}/datasets/{dataset_name}/versions/{dataset_version}/files\",\n",
    "            params=params,\n",
    "        )\n",
    "\n",
    "    def get_file_url(self, dataset_name: str, dataset_version: str, file_name: str):\n",
    "        return self.__get_data(\n",
    "            f\"{self.base_url}/datasets/{dataset_name}/versions/{dataset_version}/files/{file_name}/url\"\n",
    "        )\n",
    "\n",
    "\n",
    "def download_file_from_temporary_download_url(download_url, filename):\n",
    "    try:\n",
    "        with requests.get(download_url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(filename, \"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "    except Exception:\n",
    "        logger.exception(\"Unable to download file using download URL\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    logger.info(f\"Successfully downloaded dataset file to {filename}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    api_key = \"eyJvcmciOiI1ZTU1NGUxOTI3NGE5NjAwMDEyYTNlYjEiLCJpZCI6ImE1OGI5NGZmMDY5NDRhZDNhZjFkMDBmNDBmNTQyNjBkIiwiaCI6Im11cm11cjEyOCJ9\"\n",
    "    dataset_name = \"harmonie_arome_cy40_p1\"\n",
    "    dataset_version = \"0.2\"\n",
    "    logger.info(f\"Fetching latest file of {dataset_name} version {dataset_version}\")\n",
    "\n",
    "    api = OpenDataAPI(api_token=api_key)\n",
    "\n",
    "    # sort the files in descending order and only retrieve the first file\n",
    "    params = {\"maxKeys\": 1, \"orderBy\": \"created\", \"sorting\": \"desc\"}\n",
    "    response = api.list_files(dataset_name, dataset_version, params)\n",
    "    if \"error\" in response:\n",
    "        logger.error(f\"Unable to retrieve list of files: {response['error']}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    latest_file = response[\"files\"][0].get(\"filename\")\n",
    "    logger.info(f\"Latest file is: {latest_file}\")\n",
    "\n",
    "    # fetch the download url and download the file\n",
    "    response = api.get_file_url(dataset_name, dataset_version, latest_file)\n",
    "    download_file_from_temporary_download_url(response[\"temporaryDownloadUrl\"], latest_file)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unpack_tar_file(tar_path):\n",
    "    # Create destination folder path\n",
    "    dest_folder = os.path.join(os.path.dirname(tar_path), os.path.basename(tar_path).rsplit('.', 1)[0])\n",
    "    os.makedirs(dest_folder, exist_ok=True)  # Ensure the destination folder exists\n",
    "    \n",
    "    # Extract all contents of file in destination folder path\n",
    "    with tarfile.open(tar_path, \"r\") as tar:\n",
    "        tar.extractall(path=dest_folder)\n",
    "\n",
    "# Replace with the path to your tar file\n",
    "tar_path = \"harm40_v1_p1_2024052906.tar\"\n",
    "unpack_tar_file(tar_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         file_name            datetime  latitude  longitude  \\\n",
      "0   HA40_N25_202405290600_00000_GB 2024-05-29 06:00:00    51.438      5.476   \n",
      "1   HA40_N25_202405290600_00100_GB 2024-05-29 07:00:00    51.438      5.476   \n",
      "2   HA40_N25_202405290600_00200_GB 2024-05-29 08:00:00    51.438      5.476   \n",
      "3   HA40_N25_202405290600_00300_GB 2024-05-29 09:00:00    51.438      5.476   \n",
      "4   HA40_N25_202405290600_00400_GB 2024-05-29 10:00:00    51.438      5.476   \n",
      "5   HA40_N25_202405290600_00500_GB 2024-05-29 11:00:00    51.438      5.476   \n",
      "6   HA40_N25_202405290600_00600_GB 2024-05-29 12:00:00    51.438      5.476   \n",
      "7   HA40_N25_202405290600_00700_GB 2024-05-29 13:00:00    51.438      5.476   \n",
      "8   HA40_N25_202405290600_00800_GB 2024-05-29 14:00:00    51.438      5.476   \n",
      "9   HA40_N25_202405290600_00900_GB 2024-05-29 15:00:00    51.438      5.476   \n",
      "10  HA40_N25_202405290600_01000_GB 2024-05-29 16:00:00    51.438      5.476   \n",
      "11  HA40_N25_202405290600_01100_GB 2024-05-29 17:00:00    51.438      5.476   \n",
      "12  HA40_N25_202405290600_01200_GB 2024-05-29 18:00:00    51.438      5.476   \n",
      "13  HA40_N25_202405290600_01300_GB 2024-05-29 19:00:00    51.438      5.476   \n",
      "14  HA40_N25_202405290600_01400_GB 2024-05-29 20:00:00    51.438      5.476   \n",
      "15  HA40_N25_202405290600_01500_GB 2024-05-29 21:00:00    51.438      5.476   \n",
      "16  HA40_N25_202405290600_01600_GB 2024-05-29 22:00:00    51.438      5.476   \n",
      "17  HA40_N25_202405290600_01700_GB 2024-05-29 23:00:00    51.438      5.476   \n",
      "18  HA40_N25_202405290600_01800_GB 2024-05-30 00:00:00    51.438      5.476   \n",
      "19  HA40_N25_202405290600_01900_GB 2024-05-30 01:00:00    51.438      5.476   \n",
      "20  HA40_N25_202405290600_02000_GB 2024-05-30 02:00:00    51.438      5.476   \n",
      "21  HA40_N25_202405290600_02100_GB 2024-05-30 03:00:00    51.438      5.476   \n",
      "22  HA40_N25_202405290600_02200_GB 2024-05-30 04:00:00    51.438      5.476   \n",
      "23  HA40_N25_202405290600_02300_GB 2024-05-30 05:00:00    51.438      5.476   \n",
      "24  HA40_N25_202405290600_02400_GB 2024-05-30 06:00:00    51.438      5.476   \n",
      "25  HA40_N25_202405290600_02500_GB 2024-05-30 07:00:00    51.438      5.476   \n",
      "26  HA40_N25_202405290600_02600_GB 2024-05-30 08:00:00    51.438      5.476   \n",
      "27  HA40_N25_202405290600_02700_GB 2024-05-30 09:00:00    51.438      5.476   \n",
      "28  HA40_N25_202405290600_02800_GB 2024-05-30 10:00:00    51.438      5.476   \n",
      "29  HA40_N25_202405290600_02900_GB 2024-05-30 11:00:00    51.438      5.476   \n",
      "30  HA40_N25_202405290600_03000_GB 2024-05-30 12:00:00    51.438      5.476   \n",
      "31  HA40_N25_202405290600_03100_GB 2024-05-30 13:00:00    51.438      5.476   \n",
      "32  HA40_N25_202405290600_03200_GB 2024-05-30 14:00:00    51.438      5.476   \n",
      "33  HA40_N25_202405290600_03300_GB 2024-05-30 15:00:00    51.438      5.476   \n",
      "34  HA40_N25_202405290600_03400_GB 2024-05-30 16:00:00    51.438      5.476   \n",
      "35  HA40_N25_202405290600_03500_GB 2024-05-30 17:00:00    51.438      5.476   \n",
      "36  HA40_N25_202405290600_03600_GB 2024-05-30 18:00:00    51.438      5.476   \n",
      "37  HA40_N25_202405290600_03700_GB 2024-05-30 19:00:00    51.438      5.476   \n",
      "38  HA40_N25_202405290600_03800_GB 2024-05-30 20:00:00    51.438      5.476   \n",
      "39  HA40_N25_202405290600_03900_GB 2024-05-30 21:00:00    51.438      5.476   \n",
      "40  HA40_N25_202405290600_04000_GB 2024-05-30 22:00:00    51.438      5.476   \n",
      "41  HA40_N25_202405290600_04100_GB 2024-05-30 23:00:00    51.438      5.476   \n",
      "42  HA40_N25_202405290600_04200_GB 2024-05-31 00:00:00    51.438      5.476   \n",
      "43  HA40_N25_202405290600_04300_GB 2024-05-31 01:00:00    51.438      5.476   \n",
      "44  HA40_N25_202405290600_04400_GB 2024-05-31 02:00:00    51.438      5.476   \n",
      "45  HA40_N25_202405290600_04500_GB 2024-05-31 03:00:00    51.438      5.476   \n",
      "46  HA40_N25_202405290600_04600_GB 2024-05-31 04:00:00    51.438      5.476   \n",
      "47  HA40_N25_202405290600_04700_GB 2024-05-31 05:00:00    51.438      5.476   \n",
      "48  HA40_N25_202405290600_04800_GB 2024-05-31 06:00:00    51.438      5.476   \n",
      "\n",
      "    temperature  globalRadiation  windSpeed  \n",
      "0     15.325098              NaN        NaN  \n",
      "1     15.494775     1.581781e+05   5.672487  \n",
      "2     16.323877     1.081657e+06   5.439941  \n",
      "3     16.175439     1.808375e+06   4.813988  \n",
      "4     15.603662     2.045352e+06   4.778458  \n",
      "5     16.275293     2.560910e+06   5.588524  \n",
      "6     18.080713     4.088419e+06   6.341169  \n",
      "7     17.291162     5.139857e+06   6.473440  \n",
      "8     17.875391     6.054479e+06   5.572881  \n",
      "9     16.795313     6.651873e+06   3.110974  \n",
      "10    16.635889     7.400410e+06   3.803772  \n",
      "11    16.954248     7.792750e+06   2.974934  \n",
      "12    17.550439     8.662550e+06   2.811468  \n",
      "13    17.238428     9.039462e+06   1.480503  \n",
      "14    15.867212     9.089458e+06   0.787742  \n",
      "15    14.629053     9.089458e+06   0.748354  \n",
      "16    14.289209     9.089458e+06   1.476651  \n",
      "17    14.308374     9.089458e+06   1.482501  \n",
      "18    13.602930     9.089458e+06   1.082031  \n",
      "19    13.601709     9.089458e+06   1.056490  \n",
      "20    13.408105     9.089458e+06   1.436963  \n",
      "21    13.840356     9.089458e+06   1.858752  \n",
      "22    13.630518     9.095992e+06   2.622691  \n",
      "23    13.165430     9.182242e+06   2.663726  \n",
      "24    13.833398     9.665175e+06   2.340967  \n",
      "25    14.532739     1.048960e+07   2.328582  \n",
      "26    14.281396     1.084039e+07   2.486603  \n",
      "27    13.866357     1.108795e+07   1.780977  \n",
      "28    13.878809     1.132832e+07   1.555509  \n",
      "29    15.854150     1.253883e+07   1.279426  \n",
      "30    18.511865     1.511577e+07   1.032668  \n",
      "31    16.165430     1.584788e+07   3.955417  \n",
      "32    17.442041     1.620320e+07   2.447228  \n",
      "33    17.146631     1.674643e+07   4.113404  \n",
      "34    17.267969     1.785500e+07   3.990990  \n",
      "35    17.146875     1.893590e+07   3.995403  \n",
      "36    16.339990     1.948233e+07   3.639024  \n",
      "37    15.066797     1.961191e+07   3.954102  \n",
      "38    14.316064     1.962803e+07   2.249975  \n",
      "39    13.440088     1.962803e+07   2.182711  \n",
      "40    13.292871     1.962803e+07   1.959982  \n",
      "41    13.621973     1.962803e+07   1.906608  \n",
      "42    13.625879     1.962803e+07   1.324893  \n",
      "43    13.478662     1.962803e+07   1.974082  \n",
      "44    13.483057     1.962803e+07   1.676004  \n",
      "45    13.535303     1.962803e+07   1.935184  \n",
      "46    13.529932     1.962761e+07   2.013104  \n",
      "47    13.658350     1.963764e+07   2.432938  \n",
      "48    13.947412     1.977318e+07   3.082790  \n"
     ]
    }
   ],
   "source": [
    "# Eindhoven\n",
    "eindhoven_lat = 51.4416\n",
    "eindhoven_lon = 5.4697\n",
    "\n",
    "# Folder grib files\n",
    "grib_folder = r\"C:\\Users\\20193362\\Desktop\\InterProject\\InterdisciplinaryProject\\energy_prediction\\harm40_v1_p1_2024052906\"\n",
    "\n",
    "# List needed parameters, see code matrix KNMI\n",
    "parameters = {\"temperature\": \"11\", \"windU\": \"33\", \"windV\": \"34\", \"globalRadiation\":  \"117\"}\n",
    "\n",
    "# Initialize list to hold the data\n",
    "data_list = []\n",
    "\n",
    "# Loop over each file \n",
    "for file_name in os.listdir(grib_folder):\n",
    "    if file_name.endswith('_GB'):\n",
    "        grib_file = os.path.join(grib_folder, file_name)\n",
    "        grbs = pygrib.open(grib_file)\n",
    "        \n",
    "        # Retrieve the lat/lon grid\n",
    "        first_message = grbs.message(1)\n",
    "        lats, lons = first_message.latlons()\n",
    "        \n",
    "        # Find the closest grid point\n",
    "        distance = np.sqrt((lats - eindhoven_lat)**2 + (lons - eindhoven_lon)**2)\n",
    "        min_index = distance.argmin()\n",
    "        nearest_point_lat = lats.flat[min_index]\n",
    "        nearest_point_lon = lons.flat[min_index]\n",
    "\n",
    "        data_date = str(first_message.dataDate)  # Format: YYYYMMDD\n",
    "        data_time = first_message.dataTime  # Format: HHMM\n",
    "        \n",
    "        # Create the base datetime object from dataDate and dataTime\n",
    "        base_datetime = datetime.strptime(f\"{data_date} {data_time:04d}\", \"%Y%m%d %H%M\")\n",
    "        step_range = float(first_message.stepRange)\n",
    "        valid_datetime = base_datetime + timedelta(hours=step_range)\n",
    "        \n",
    "        # Initialize a dictionary to hold the data for this file\n",
    "        data_dict = {\n",
    "            'file_name': file_name,\n",
    "            'datetime': valid_datetime,\n",
    "            'latitude': nearest_point_lat,\n",
    "            'longitude': nearest_point_lon\n",
    "        }\n",
    "        \n",
    "        # Extract data for each parameter\n",
    "        for key in parameters:\n",
    "            try:\n",
    "                grb_message = grbs.select(parameterName=params[key])[0] # First instance\n",
    "                parameter_name = key\n",
    "                eindhoven_value = grb_message.values.flat[min_index]\n",
    "                data_dict[parameter_name] = eindhoven_value\n",
    "            except (IndexError, ValueError):\n",
    "                data_dict[parameter_name] = np.nan # When parameter is not found in grib file\n",
    "        \n",
    "        grbs.close()\n",
    "        \n",
    "        # Append dictionary to list\n",
    "        data_list.append(data_dict)\n",
    "\n",
    "# Convert list of dictionaries to DF\n",
    "gribData = pd.DataFrame(data_list)\n",
    "df = gribData.copy()\n",
    "df['windSpeed'] = np.sqrt(df['windU']**2 + df['windV']**2)\n",
    "df['temperature'] = df['temperature'] - 272.15\n",
    "df = df.drop(['windU', 'windV'], axis=1)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
