{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use to run models for pv detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "from skimage.draw import polygon, polygon_perimeter\n",
    "from skimage import measure\n",
    "from skimage import io\n",
    "\n",
    "from matplotlib.patches import Circle, Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "from roboflow import Roboflow \n",
    "\n",
    "import torch.nn as nn \n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from models.image_recongnition import BaseModel \n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "script_dir = os.path.dirname(current_directory + 'models')  \n",
    "base_cnn_dir = os.path.join(script_dir, 'architectures')  \n",
    "sys.path.append(base_cnn_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "\n",
    "DATASET_KEY = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=undefined&ref=undefined\n",
      "loading Roboflow workspace...\n"
     ]
    },
    {
     "ename": "RoboflowError",
     "evalue": "{\n    \"error\": {\n        \"message\": \"This method requires your API key.\",\n        \"type\": \"OAuthException\",\n        \"hint\": \"You may pass a token as `api_key` in the request body or query parameters, or through an `Authorization: Bearer <api_key>` header.\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRoboflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNL-Solar-Panel-Seg-1\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      9\u001b[0m     rf \u001b[38;5;241m=\u001b[39m Roboflow(api_key\u001b[38;5;241m=\u001b[39mDATASET_KEY)\n\u001b[0;32m---> 10\u001b[0m     project \u001b[38;5;241m=\u001b[39m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkspace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43melectasolar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mproject(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnl-solar-panel-seg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     version \u001b[38;5;241m=\u001b[39m project\u001b[38;5;241m.\u001b[39mversion(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoco-segmentation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/TuE/InterdisciplinaryProject/.venv/lib/python3.11/site-packages/roboflow/__init__.py:259\u001b[0m, in \u001b[0;36mRoboflow.workspace\u001b[0;34m(self, the_workspace)\u001b[0m\n\u001b[1;32m    256\u001b[0m workspace_api_key \u001b[38;5;241m=\u001b[39m load_roboflow_api_key(the_workspace)\n\u001b[1;32m    257\u001b[0m api_key \u001b[38;5;241m=\u001b[39m workspace_api_key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n\u001b[0;32m--> 259\u001b[0m list_projects \u001b[38;5;241m=\u001b[39m \u001b[43mrfapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_workspace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthe_workspace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Workspace(list_projects, api_key, the_workspace, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_format)\n",
      "File \u001b[0;32m~/TuE/InterdisciplinaryProject/.venv/lib/python3.11/site-packages/roboflow/adapters/rfapi.py:24\u001b[0m, in \u001b[0;36mget_workspace\u001b[0;34m(api_key, workspace_url)\u001b[0m\n\u001b[1;32m     22\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RoboflowError(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     25\u001b[0m result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mRoboflowError\u001b[0m: {\n    \"error\": {\n        \"message\": \"This method requires your API key.\",\n        \"type\": \"OAuthException\",\n        \"hint\": \"You may pass a token as `api_key` in the request body or query parameters, or through an `Authorization: Bearer <api_key>` header.\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "# Load data from roboflow \n",
    "if not os.path.exists(r'NL-Solar-Panel-Seg-1'):\n",
    "    rf = Roboflow(api_key=DATASET_KEY)\n",
    "    project = rf.workspace(\"electasolar\").project(\"nl-solar-panel-seg\")\n",
    "    version = project.version(1)\n",
    "    dataset = version.download(\"coco-segmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Definer the loaders here\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model, \u001b[43mtrain_loader\u001b[49m, val_loader)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from base_cnn import ImageRecognitionModel \n",
    "from image_recongnition import BaseModel\n",
    "\n",
    "model = ImageRecognitionModel(hidden_size=32, num_classes=10)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "metrics = {\"accuracy\": nn.CrossEntropyLoss()}\n",
    "model = BaseModel(model, loss_fn, optimizer, scheduler, metrics)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=10)\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5ARIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
