{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use to run models for pv detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "from skimage.draw import polygon, polygon_perimeter\n",
    "from skimage import measure\n",
    "from skimage import io\n",
    "\n",
    "from matplotlib.patches import Circle, Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "from roboflow import Roboflow \n",
    "\n",
    "import torch.nn as nn \n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import image_recongnition \n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "script_dir = os.path.dirname(current_directory + 'models')  \n",
    "base_cnn_dir = os.path.join(script_dir, 'architectures')  \n",
    "sys.path.append(base_cnn_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from roboflow \n",
    "\n",
    "dotenv.load_dotenv()\n",
    "DATASET_KEY = os.getenv('API_KEY')\n",
    "if not os.path.exists(r'NL-Solar-Panel-Seg-1'):\n",
    "    rf = Roboflow(api_key=DATASET_KEY)\n",
    "    project = rf.workspace(\"electasolar\").project(\"nl-solar-panel-seg\")\n",
    "    version = project.version(1)\n",
    "    dataset = version.download(\"coco-segmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Definer the loaders here\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model, \u001b[43mtrain_loader\u001b[49m, val_loader)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from base_cnn import ImageRecognitionModel \n",
    "from image_recongnition import BaseModel\n",
    "\n",
    "model = ImageRecognitionModel(hidden_size=32, num_classes=10)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "metrics = {\"accuracy\": nn.CrossEntropyLoss()}\n",
    "model = BaseModel(model, loss_fn, optimizer, scheduler, metrics)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=10)\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5ARIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
