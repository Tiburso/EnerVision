{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.germany_dataset import load_image_and_labels\n",
    "from image_helpers import polygons_to_bounding_boxes, polygons_to_masks, mask_to_polygons\n",
    "from torchvision.utils import draw_segmentation_masks, draw_bounding_boxes\n",
    "from torchvision.tv_tensors import BoundingBoxes, Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_and_mask(image, masks, ax=None):\n",
    "    # Convert images to uint8\n",
    "    image = (image * 255).byte()\n",
    "    \n",
    "    # Convert masks to bool\n",
    "    masks = masks.bool()\n",
    "    \n",
    "    # Draw the masks on the image\n",
    "    image_with_masks = draw_segmentation_masks(image, masks)\n",
    "    \n",
    "    # Convert to PIL image\n",
    "    image_with_masks = image_with_masks.permute(1, 2, 0)\n",
    "    \n",
    "    if ax is None:\n",
    "        plt.imshow(image_with_masks)\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        ax.imshow(image_with_masks)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.solar_dk_dataset import SolarDKDataset\n",
    "from dataloaders.nl_dataset import CocoSegmentationDataset\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "solar_dk_folder = \"data/solardk_dataset_neurips_v2/gentofte_trainval/train\"\n",
    "coco_folder = \"data/NL-Solar-Panel-Seg-1/train\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "    transforms.Resize(640, interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "solar_dk_dataset = SolarDKDataset(solar_dk_folder, transform=transform, normalize=True)\n",
    "coco_dataset = CocoSegmentationDataset(coco_folder, transform=transform, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert mean and std to tensors\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "mean_tensor = torch.tensor(mean).view(1, 3, 1, 1)\n",
    "std_tensor = torch.tensor(std).view(1, 3, 1, 1)\n",
    "\n",
    "inv_transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0., 0., 0.], std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "    transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[ 1., 1., 1.]),\n",
    "])\n",
    "\n",
    "full_dataset = solar_dk_dataset + coco_dataset\n",
    "\n",
    "image, mask = coco_dataset[10]\n",
    "\n",
    "print(image.shape, mask.shape)\n",
    "\n",
    "plot_image_and_mask(inv_transform(image), mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from models.architectures import DeepLabModel\n",
    "\n",
    "train_dataloader = DataLoader(full_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "model = DeepLabModel(num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from models.base import BaseModel\n",
    "from models.architectures.deep_lab import DeepLabModel\n",
    "# from models.architectures.mask_rcnn import MaskRCNNModel\n",
    "from models.architectures.unet import UNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_dataloader:\n",
    "    # Print the size of the image and label\n",
    "    print(image.size(), label.size())  \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model = BaseModel(model, torch.nn.CrossEntropyLoss(), optimizer=torch.optim.Adam(model.parameters(), lr=0.001))\n",
    "image, mask = next(iter(train_dataloader))\n",
    "image, mask = next(iter(train_dataloader))\n",
    "\n",
    "model.eval()\n",
    "output = base_model(image)# Turn mask into two channel mask\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch.losses import DiceLoss, JaccardLoss\n",
    "from torch import nn\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "        self.dice_loss = DiceLoss(mode=\"multiclass\")\n",
    "        self.jaccard_loss = JaccardLoss(mode=\"multiclass\")\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        cross_entropy_loss = self.cross_entropy(y_pred, y_true)\n",
    "        \n",
    "        # Convert the mask from 2 channels to 1 channel\n",
    "        y_true = torch.argmax(y_true, dim=1)\n",
    "        \n",
    "        dice_loss = self.dice_loss(y_pred, y_true)\n",
    "        jaccard_loss = self.jaccard_loss(y_pred, y_true)\n",
    "        \n",
    "        print(f\"Cross entropy loss: {cross_entropy_loss}\")\n",
    "        print(f\"Dice loss: {dice_loss}\")\n",
    "        print(f\"Jaccard loss: {jaccard_loss}\")\n",
    "\n",
    "        return cross_entropy_loss + 2 * dice_loss + 3 * jaccard_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from segmentation_models_pytorch.metrics import iou_score, get_stats\n",
    "from losses import AsymmetricUnifiedFocalLoss\n",
    "\n",
    "loss_fn = AsymmetricUnifiedFocalLoss(weight=0.3, delta=0.25, gamma=2)\n",
    "loss = loss_fn(output, mask)\n",
    "loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sigmoid\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# mask = mask.argmax(dim=1)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmask\u001b[49m\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m      8\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjaccard_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: jaccard_index(output, mask, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy(output, mask,task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdice\u001b[39m\u001b[38;5;124m\"\u001b[39m: dice(output, mask\u001b[38;5;241m.\u001b[39mint())\n\u001b[1;32m     15\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mask' is not defined"
     ]
    }
   ],
   "source": [
    "from torchmetrics.functional.classification import accuracy, precision, recall, f1_score, jaccard_index, dice\n",
    "from torch import sigmoid\n",
    "\n",
    "# mask = mask.argmax(dim=1)\n",
    "print(mask.unique())\n",
    "print(output.argmax(dim=1).unique())\n",
    "\n",
    "metrics = {\n",
    "    \"jaccard_index\": jaccard_index(output, mask, task=\"multiclass\", num_classes=2),\n",
    "    \"accuracy\": accuracy(output, mask,task=\"multiclass\", num_classes=2),\n",
    "    \"precision\": precision(output, mask,task=\"multiclass\", num_classes=2),\n",
    "    \"recall\": recall(output, mask,task=\"multiclass\", num_classes=2),\n",
    "    \"f1_score\": f1_score(output, mask,task=\"multiclass\", num_classes=2),\n",
    "    \"dice\": dice(output, mask.int())\n",
    "}\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/solardk_dataset_neurips_v2/herlev_test/train/positive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 19\u001b[0m\n\u001b[1;32m     13\u001b[0m inv_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     14\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m0.225\u001b[39m]),\n\u001b[1;32m     15\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.406\u001b[39m], std\u001b[38;5;241m=\u001b[39m[ \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m1.\u001b[39m]),\n\u001b[1;32m     16\u001b[0m ])\n\u001b[1;32m     18\u001b[0m test_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/solardk_dataset_neurips_v2/herlev_test/train\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mSolarDKDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# test_folder = \"data/NL-Solar-Panel-Seg-1/test\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# test_dataset = CocoSegmentationDataset(test_folder)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m BaseModel\u001b[38;5;241m.\u001b[39mload_from_checkpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlightning_logs/version_211837/checkpoints/last.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/InterdisciplinaryProject/dataloaders/solar_dk_dataset.py:12\u001b[0m, in \u001b[0;36mSolarDKDataset.__init__\u001b[0;34m(self, image_dir, transform, normalize)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, image_dir, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Get all files in the image directory either in the positive or negative folders\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive_files \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnegative_files \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Concat both lists\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/solardk_dataset_neurips_v2/herlev_test/train/positive'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.base import BaseModel\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from dataloaders.solar_dk_dataset import SolarDKDataset\n",
    "from dataloaders.nl_dataset import CocoSegmentationDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchmetrics.functional import jaccard_index, accuracy, precision, recall, f1_score, dice\n",
    "\n",
    "from sklearn.metrics import jaccard_score, precision_score\n",
    "\n",
    "inv_transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0., 0., 0.], std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "    transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[ 1., 1., 1.]),\n",
    "])\n",
    "\n",
    "test_folder = \"data/solardk_dataset_neurips_v2/gentofte_trainval/train\"\n",
    "test_dataset = SolarDKDataset(test_folder)\n",
    "\n",
    "# test_folder = \"data/NL-Solar-Panel-Seg-1/test\"\n",
    "# test_dataset = CocoSegmentationDataset(test_folder)\n",
    "\n",
    "model = BaseModel.load_from_checkpoint(\"lightning_logs/version_211837/checkpoints/last.ckpt\")\n",
    "\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "loss_fn = CombinedLoss()\n",
    "\n",
    "task = \"multiclass\"\n",
    "num_classes = 2\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    iterator = iter(test_loader)\n",
    "    image, label = next(iterator)\n",
    "    output = model(image)\n",
    "   \n",
    "    image = inv_transform(image)\n",
    "    label = model.model.target(label)\n",
    "    loss = loss_fn(output, label)\n",
    "    \n",
    "    label = label.argmax(dim=1)\n",
    "    \n",
    "    print(f\"Loss: {loss.item()}\")          \n",
    "    print(f\"Dice Score: {dice(output, label.int())}\")\n",
    "    print(f\"Jaccard Index: {jaccard_index(output, label, task=task, num_classes=num_classes, average='macro')}\")\n",
    "    print(f\"Precision: {precision(output, label, task=task, num_classes=  num_classes, average='macro')}\")\n",
    "    print(f\"Accuracy: {accuracy(output, label, task=task, num_classes=num_classes)}\")\n",
    "    print(f\"Recall: {recall(output, label, task=task, num_classes=num_classes)}\")\n",
    "    print(f\"F1 Score: {f1_score(output, label, task=task, num_classes=num_classes)}\")\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "    \n",
    "    ax[0].imshow(image[0].permute(1, 2, 0))\n",
    "    ax[0].set_title(\"Image\")\n",
    "    \n",
    "    ax[1].imshow(label.squeeze(), cmap=\"gray\")\n",
    "    ax[1].set_title(\"Label\")     \n",
    "    \n",
    "    ax[2].imshow(output.argmax(dim=1).squeeze(), cmap=\"gray\")\n",
    "    ax[2].set_title(\"Prediction\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
