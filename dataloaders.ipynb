{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.germany_dataset import load_image_and_labels\n",
    "from image_helpers import polygons_to_bounding_boxes, polygons_to_masks, mask_to_polygons\n",
    "from torchvision.utils import draw_segmentation_masks, draw_bounding_boxes\n",
    "from torchvision.tv_tensors import BoundingBoxes, Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_and_mask(image, masks, ax=None):\n",
    "    # Convert images to uint8\n",
    "    image = (image * 255).byte()\n",
    "    \n",
    "    # Convert masks to bool\n",
    "    masks = masks.bool()\n",
    "    \n",
    "    # Draw the masks on the image\n",
    "    image_with_masks = draw_segmentation_masks(image, masks)\n",
    "    \n",
    "    # Convert to PIL image\n",
    "    image_with_masks = image_with_masks.permute(1, 2, 0)\n",
    "    \n",
    "    if ax is None:\n",
    "        plt.imshow(image_with_masks)\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        ax.imshow(image_with_masks)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.solar_dk_dataset import SolarDKDataset\n",
    "from dataloaders.nl_dataset import CocoSegmentationDataset\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "solar_dk_folder = \"data/solardk_dataset_neurips_v2/gentofte_trainval/train\"\n",
    "coco_folder = \"data/NL-Solar-Panel-Seg-1/train\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "    transforms.Resize(640, interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "solar_dk_dataset = SolarDKDataset(solar_dk_folder, transform=transform, normalize=True)\n",
    "coco_dataset = CocoSegmentationDataset(coco_folder, transform=transform, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert mean and std to tensors\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "mean_tensor = torch.tensor(mean).view(1, 3, 1, 1)\n",
    "std_tensor = torch.tensor(std).view(1, 3, 1, 1)\n",
    "\n",
    "inv_transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0., 0., 0.], std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "    transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[ 1., 1., 1.]),\n",
    "])\n",
    "\n",
    "full_dataset = solar_dk_dataset + coco_dataset\n",
    "\n",
    "image, mask = coco_dataset[10]\n",
    "\n",
    "print(image.shape, mask.shape)\n",
    "\n",
    "plot_image_and_mask(inv_transform(image), mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from models.architectures import DeepLabModel\n",
    "\n",
    "train_dataloader = DataLoader(full_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "model = DeepLabModel(num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from models.base import BaseModel\n",
    "from models.architectures.deep_lab import DeepLabModel\n",
    "# from models.architectures.mask_rcnn import MaskRCNNModel\n",
    "from models.architectures.unet import UNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_dataloader:\n",
    "    # Print the size of the image and label\n",
    "    print(image.size(), label.size())  \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model = BaseModel(model, torch.nn.CrossEntropyLoss(), optimizer=torch.optim.Adam(model.parameters(), lr=0.001))\n",
    "image, mask = next(iter(train_dataloader))\n",
    "image, mask = next(iter(train_dataloader))\n",
    "\n",
    "model.eval()\n",
    "output = base_model(image)# Turn mask into two channel mask\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch.losses import DiceLoss, JaccardLoss\n",
    "from torch import nn\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "        self.dice_loss = DiceLoss(mode=\"multiclass\")\n",
    "        self.jaccard_loss = JaccardLoss(mode=\"multiclass\")\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        cross_entropy_loss = self.cross_entropy(y_pred, y_true)\n",
    "        \n",
    "        # Convert the mask from 2 channels to 1 channel\n",
    "        y_true = torch.argmax(y_true, dim=1)\n",
    "        \n",
    "        dice_loss = self.dice_loss(y_pred, y_true)\n",
    "        jaccard_loss = self.jaccard_loss(y_pred, y_true)\n",
    "        \n",
    "        # print(f\"Cross entropy loss: {cross_entropy_loss}\")\n",
    "        # print(f\"Dice loss: {dice_loss}\")\n",
    "        # print(f\"Jaccard loss: {jaccard_loss}\")\n",
    "\n",
    "        return cross_entropy_loss + 2 * dice_loss + 3 * jaccard_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from segmentation_models_pytorch.metrics import iou_score, get_stats\n",
    "from losses import AsymmetricUnifiedFocalLoss\n",
    "\n",
    "loss_fn = AsymmetricUnifiedFocalLoss(weight=0.3, delta=0.25, gamma=2)\n",
    "loss = loss_fn(output, mask)\n",
    "loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.classification import accuracy, precision, recall, f1_score, jaccard_index, dice\n",
    "from torch import sigmoid\n",
    "\n",
    "# mask = mask.argmax(dim=1)\n",
    "print(mask.unique())\n",
    "print(output.argmax(dim=1).unique())\n",
    "\n",
    "metrics = {\n",
    "    \"jaccard_index\": jaccard_index(output, mask, task=\"multiclass\", num_classes=2),\n",
    "    \"accuracy\": accuracy(output, mask,task=\"multiclass\", num_classes=2),\n",
    "    \"precision\": precision(output, mask,task=\"multiclass\", num_classes=2),\n",
    "    \"recall\": recall(output, mask,task=\"multiclass\", num_classes=2),\n",
    "    \"f1_score\": f1_score(output, mask,task=\"multiclass\", num_classes=2),\n",
    "    \"dice\": dice(output, mask.int())\n",
    "}\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/germanty_dataset/google/img'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 51\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# test_folder = \"data/solardk_dataset_neurips_v2/herlev_test/test\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# test_dataset = SolarDKDataset(test_folder, total_samples=500)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# test_dataset = CocoSegmentationDataset(test_folder)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m test_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/germanty_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 51\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mGermanyDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     55\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgs/eindhoven_satellite.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/InterdisciplinaryProject/dataloaders/germany_dataset.py:16\u001b[0m, in \u001b[0;36mGermanyDataset.__init__\u001b[0;34m(self, folder_path, transform)\u001b[0m\n\u001b[1;32m     13\u001b[0m google_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m ign_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mign\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgoogle_images \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgoogle_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mign_images \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ign_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgoogle_images \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mign_images\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/germanty_dataset/google/img'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.base import BaseModel\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from losses import CombinedLoss\n",
    "from segmentation_models_pytorch.losses import DiceLoss, JaccardLoss\n",
    "\n",
    "from dataloaders.solar_dk_dataset import SolarDKDataset\n",
    "from dataloaders.nl_dataset import CocoSegmentationDataset\n",
    "from dataloaders.germany_dataset import GermanyDataset\n",
    "\n",
    "from torchmetrics.functional import jaccard_index, accuracy, precision, recall, f1_score, dice\n",
    "\n",
    "from sklearn.metrics import jaccard_score, precision_score\n",
    "\n",
    "class LossJaccard(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss = JaccardLoss(mode=\"multiclass\")\n",
    "\n",
    "    def forward(self, y_hat, y):\n",
    "        y = y.argmax(dim=1)\n",
    "        return self.loss(y_hat, y)\n",
    "\n",
    "inv_transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0., 0., 0.], std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "    transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[ 1., 1., 1.]),\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "    transforms.Resize((640, 640), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# test_folder = \"data/solardk_dataset_neurips_v2/herlev_test/test\"\n",
    "# test_dataset = SolarDKDataset(test_folder, total_samples=500)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# test_folder = \"data/NL-Solar-Panel-Seg-1/test\"\n",
    "# test_dataset = CocoSegmentationDataset(test_folder)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_folder = \"data/germany_dataset\"\n",
    "test_dataset = GermanyDataset(test_folder)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "image = Image.open(\"imgs/eindhoven_satellite.png\").convert(\"RGB\")\n",
    "image = transform(image).unsqueeze(0)\n",
    "\n",
    "model = BaseModel.load_from_checkpoint(\"lightning_logs/version_251115/checkpoints/last.ckpt\")\n",
    "# checkpoint = torch.load(\"lightning_logs/version_251115/checkpoints/last.ckpt\", map_location=torch.device(\"cpu\"))\n",
    "\n",
    "task = \"multiclass\"\n",
    "num_classes = 2\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    iterator = iter(test_loader)\n",
    "    image, label = next(iterator)\n",
    "    output = model(image)\n",
    "   \n",
    "    image = inv_transform(image)\n",
    "    # label = model.model.target(label)\n",
    "    # # loss = loss_fn(output, label)\n",
    "    \n",
    "    # label = label.argmax(dim=1)\n",
    "    \n",
    "    # # print(f\"Loss: {loss.item()}\")          \n",
    "    # print(f\"Dice Score: {dice(output, label.int())}\")\n",
    "    # print(f\"Jaccard Index: {jaccard_index(output, label, task=task, num_classes=num_classes, average='macro')}\")\n",
    "    # print(f\"Precision: {precision(output, label, task=task, num_classes=  num_classes, average='macro')}\")\n",
    "    # print(f\"Accuracy: {accuracy(output, label, task=task, num_classes=num_classes)}\")\n",
    "    # print(f\"Recall: {recall(output, label, task=task, num_classes=num_classes)}\")\n",
    "    # print(f\"F1 Score: {f1_score(output, label, task=task, num_classes=num_classes)}\")\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "        \n",
    "    ax[0].imshow(image[0].permute(1, 2, 0))\n",
    "    ax[0].set_title(\"Image\")\n",
    "    \n",
    "    ax[1].imshow(label.squeeze(), cmap=\"gray\")\n",
    "    ax[1].set_title(\"Label\")     \n",
    "    \n",
    "    ax[2].imshow(output.argmax(dim=1).squeeze(), cmap=\"gray\")\n",
    "    ax[2].set_title(\"Prediction\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
